{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "GX1v120zn1dH",
   "metadata": {},
   "source": [
    "# CS 5542 — Week 1 Lab\n",
    "## From Data to Retrieval: GitHub → Colab → Hugging Face → Embeddings\n",
    "\n",
    "**Learning Goals:**\n",
    "- Use GitHub for collaborative analytics workflows\n",
    "- Run notebooks in Google Colab\n",
    "- Load datasets and models from Hugging Face Hub\n",
    "- Build an embedding-based retrieval system (mini-RAG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sV1ZVCVKn1dI",
   "metadata": {},
   "source": [
    "### GenAI Systems Context (Mini-RAG)\n",
    "This lab implements a **mini Retrieval-Augmented Generation (RAG)** pipeline:\n",
    "- A **Transformer encoder** produces semantic embeddings\n",
    "- A **vector index (FAISS)** enables fast retrieval\n",
    "- Retrieved context is what a downstream **LLM** would use for grounded generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NJN5CIEWn1dJ",
   "metadata": {},
   "source": [
    "## Step 1 — Environment Setup\n",
    "Install required libraries. This may take ~1 minute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2tuBUirTn1dJ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Rq6N3Pk3n1dK",
   "metadata": {},
   "source": [
    "## Step 2 — Load Dataset & Model from Hugging Face Hub\n",
    "We use a lightweight news dataset and a sentence embedding model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "udjvk02sQmg-",
   "metadata": {},
   "source": [
    "Replace you hugging face token in the empty string, on the mentioned commented line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "PHk5zPrcpZOL",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logged in to Hugging Face\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "HF_TOKEN = \"\"  # <-- REPLACE THE EMPTY STRING WITH YOUR HF TOKEN\n",
    "\n",
    "if HF_TOKEN and HF_TOKEN != \"YOUR_HF_TOKEN_HERE\":\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"✅ Logged in to Hugging Face\")\n",
    "else:\n",
    "    print(\"⚠️ No HF token provided. Public models may still work, but rate limits may apply.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shrht5bLPoJD",
   "metadata": {},
   "source": [
    "TASK\n",
    "\n",
    "1. Find out any /ag_news dataset from the huggingface.\n",
    "2. Look for \"Use this dataset\" button on the left side --> Use huggingface library option.\n",
    "3. Copy the entire code and paste in the empty cell and run it successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fr27LHPIvvus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paste your dataset code from huggingface here\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/xwjzds/ag_news_test_lemma_train1/data/train-00000-of-00001-0b72a5bbb22306d7.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fccb9dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 60 examples from the 'train' split.\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    ' '.join(row)\n",
    "    for row in df['train'].head(200).tolist()\n",
    "]\n",
    "print(f\"Selected {len(texts)} examples from the 'train' split.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QVyVj-RkxTR3",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bupbYs_yRxHH",
   "metadata": {},
   "source": [
    "TASK\n",
    "\n",
    "1. Find out the sentence-transformer -\n",
    "all-MiniLM-L6-v2 from the huggingface website.\n",
    "2. Look for \"Use this model\" button on the left side --> Use sentence-transformer library option.\n",
    "3. Copy the first 2 lines of the code and paste in the empty cell and run it successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6HFdaLj5xJ-q",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51bfd093c2d4f57947d63c3ac4dc7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de250773aba497192fd73e7a28e1fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7daca81f98f049729cb68e54cd866def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3600fdc541094c5d84c7e9879851dfb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c78e058305e44b6a4c8eec9e3e76d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f4621f74ff407c97bfa4e7fb9f2235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a473b03fdd304aacbf7a6d2602a9f6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b21ac9cc74548f19b32ca587660d2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81568a2c4f4e44a7ad70b461cc3ce17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5925614d0c481894fd94a8e8f86679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2ac48e6422428bbdaa59423740e402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "#paste your first 2 lines of the sentence-transformer library code from the hugginface to load the model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences = [\n",
    "    \"That is a happy person\",\n",
    "    \"That is a happy dog\",\n",
    "    \"That is a very happy person\",\n",
    "    \"Today is a sunny day\"\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities.shape)\n",
    "# [4, 4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7KOJ2yaXn1dL",
   "metadata": {},
   "source": [
    "## Step 3 — Create Embeddings\n",
    "These vectors represent semantic meaning and enable retrieval before generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7Mlf67Jn1dL",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23c1749dccd4d03801c7edc1f272916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (60, 384)\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(texts, show_progress_bar=True)\n",
    "print('Embedding shape:', embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bro1K0i_n1dL",
   "metadata": {},
   "source": [
    "## Step 4 — Build a Vector Index (FAISS)\n",
    "This simulates the retrieval layer in RAG systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "_jjoDQMTn1dL",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index size: 60\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(np.array(embeddings))\n",
    "print('Index size:', index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x8eF5Z3Wn1dL",
   "metadata": {},
   "source": [
    "## Step 5 — Retrieval Function\n",
    "Search for documents related to a query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dh3ihSUn1dL",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, k=3):\n",
    "    q_emb = model.encode([query])\n",
    "    distances, indices = index.search(np.array(q_emb), k)\n",
    "    return [texts[int(i)] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6rUEk-45n1dL",
   "metadata": {},
   "source": [
    "## Step 6 — Try It!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "o_bDNGUhOr5R",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 chunks retrieved for query: 'no intelligence in healthcare'\n",
      "\n",
      "1. kofe annan call iraq war illegal united nation secretary general kofi annan say week war iraq illegal question whether country could hold credible\n",
      "\n",
      "2. italian take hostage iraq report afp afp italian national work british non governmental organisation take hostage iraq italian news agency ansa report quote italian intelligence source\n",
      "\n",
      "3. perry money aps accusation arise state adult protective service agency get emergency infusion million correct kind problem arisen paso\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"no intelligence in healthcare\"\n",
    "top_chunks = search(query, k=3)\n",
    "\n",
    "print(f\"Top 3 chunks retrieved for query: '{query}'\\n\")\n",
    "for i, chunk in enumerate(top_chunks):\n",
    "    print(f\"{i+1}. {chunk}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AO-_67l4n1dM",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "In 1–2 sentences, explain how embeddings enable retrieval before generation in GenAI systems.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
